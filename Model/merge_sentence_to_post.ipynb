{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sample(fn=\"../../data/test_sample.xlsx\"):\n",
    "    data = pd.read_excel(fn)\n",
    "    return data\n",
    "\n",
    "def read_csv(fn):\n",
    "    data = pd.read_csv(fn, index_col=0)\n",
    "    return data\n",
    "\n",
    "def reorder_text(x):\n",
    "    order = x[0]\n",
    "    text = x[1]\n",
    "\n",
    "    text = np.array(text)\n",
    "    reordered_text = text[np.argsort(order)]\n",
    "    return ' '.join(reordered_text)\n",
    "\n",
    "def merge_aspect(x):\n",
    "    tmp = set()\n",
    "    for aspects in x:\n",
    "        for each in aspects:\n",
    "            tmp.add(each)\n",
    "    return list(tmp)\n",
    "\n",
    "def merge_sentiment(x):\n",
    "    max_v = float(\"-inf\")\n",
    "    for sentiment in x:\n",
    "        for each in sentiment:\n",
    "            each = int(each)\n",
    "            if each > max_v:\n",
    "                max_v = each\n",
    "    return max_v\n",
    "\n",
    "def merge_post_level_top_k(data, top_k):\n",
    "    merge_id = \"merge_id\"\n",
    "    sentence_id = \"sentence_id\"\n",
    "    text = 'text'\n",
    "    group = 'group'\n",
    "\n",
    "    # select groups whoes frequency is on the top of k.\n",
    "    top_groups = data[group].value_counts().index[: top_k]\n",
    "    data = data[data[group].isin(top_groups)]\n",
    "\n",
    "    # group_id = merge_id + sentence_id\n",
    "    splitted_id = data['id'].str.split('-')\n",
    "    data[merge_id] = splitted_id.apply(lambda x: '-'.join(x[:-1]))\n",
    "    data[sentence_id] = splitted_id.apply(lambda x: x[-1]).astype(int)\n",
    "\n",
    "    columns = [merge_id, sentence_id, text]\n",
    "    data = data[columns]\n",
    "\n",
    "    print(\"group\")\n",
    "    # group data by merge id\n",
    "    agg_data = data.groupby([merge_id]).agg(lambda x: list(x))\n",
    "\n",
    "    print(\"reorder\")\n",
    "    agg_data[text] = list(zip(agg_data[sentence_id], agg_data[text]))\n",
    "    agg_data['reordered_text'] = agg_data[text].apply(lambda x: reorder_text(x))\n",
    "    agg_data['group'] = agg_data.index.to_series().apply(lambda x: x.split('-')[0])\n",
    "\n",
    "    return agg_data\n",
    "\n",
    "\n",
    "def merge_post_level(data):\n",
    "    merge_id = \"merge_id\"\n",
    "    sentence_id = \"sentence_id\"\n",
    "    text = 'text'\n",
    "    group = 'group'\n",
    "\n",
    "    # group_id = merge_id + sentence_id\n",
    "    splitted_id = data['id'].str.split('-')\n",
    "    data[merge_id] = splitted_id.apply(lambda x: '-'.join(x[:-1]))\n",
    "    data[sentence_id] = splitted_id.apply(lambda x: x[-1]).astype(int)\n",
    "\n",
    "    columns = [merge_id, sentence_id, text]\n",
    "    data = data[columns]\n",
    "\n",
    "    print(\"group\")\n",
    "    # group data by merge id\n",
    "    agg_data = data.groupby([merge_id]).agg(lambda x: list(x))\n",
    "\n",
    "    print(\"reorder\")\n",
    "    agg_data[text] = list(zip(agg_data[sentence_id], agg_data[text]))\n",
    "    agg_data['reordered_text'] = agg_data[text].apply(lambda x: reorder_text(x))\n",
    "    agg_data['group'] = agg_data.index.to_series().apply(lambda x: x.split('-')[0])\n",
    "\n",
    "    return agg_data\n",
    "\n",
    "def merge_post_level_and_aspect_top_k(data, top_k):\n",
    "    \n",
    "    merge_id = \"merge_id\"\n",
    "    sentence_id = \"sentence_id\"\n",
    "    text = 'text'\n",
    "    group = 'group'\n",
    "    ground_truth_aspect = \"ground_truth_aspect\"\n",
    "\n",
    "    # select groups whoes frequency is on the top of k.\n",
    "    top_groups = data[group].value_counts().index[: top_k]\n",
    "    data = data[data[group].isin(top_groups)]\n",
    "\n",
    "    # group_id = merge_id + sentence_id\n",
    "    splitted_id = data['id'].str.split('-')\n",
    "    data[merge_id] = splitted_id.apply(lambda x: '-'.join(x[:-1]))\n",
    "    data[sentence_id] = splitted_id.apply(lambda x: x[-1]).astype(int)\n",
    "\n",
    "    columns = [merge_id, sentence_id, text, ground_truth_aspect]\n",
    "    data = data[columns]\n",
    "\n",
    "    print(\"group\")\n",
    "    # group data by merge id\n",
    "    agg_data = data.groupby([merge_id]).agg(lambda x: list(x))\n",
    "\n",
    "    print(\"reorder\")\n",
    "    agg_data[text] = list(zip(agg_data[sentence_id], agg_data[text]))\n",
    "    agg_data['reordered_text'] = agg_data[text].apply(lambda x: reorder_text(x))\n",
    "    agg_data['group'] = agg_data.index.to_series().apply(lambda x: x.split('-')[0])\n",
    "    agg_data['merged_aspects'] = agg_data[ground_truth_aspect].apply(lambda x: merge_aspect(x))    \n",
    "\n",
    "    return agg_data    \n",
    "\n",
    "def merge_post_level_and_aspect_top_k(data, top_k):\n",
    "    \n",
    "    merge_id = \"merge_id\"\n",
    "    sentence_id = \"sentence_id\"\n",
    "    text = 'text'\n",
    "    group = 'group'\n",
    "    ground_truth_aspect = \"ground_truth_aspect\"\n",
    "\n",
    "    # select groups whoes frequency is on the top of k.\n",
    "    top_groups = data[group].value_counts().index[: top_k]\n",
    "    data = data[data[group].isin(top_groups)]\n",
    "\n",
    "    # group_id = merge_id + sentence_id\n",
    "    splitted_id = data['id'].str.split('-')\n",
    "    data[merge_id] = splitted_id.apply(lambda x: '-'.join(x[:-1]))\n",
    "    data[sentence_id] = splitted_id.apply(lambda x: x[-1]).astype(int)\n",
    "\n",
    "    columns = [merge_id, sentence_id, text, ground_truth_aspect]\n",
    "    data = data[columns]\n",
    "\n",
    "    print(\"group\")\n",
    "    # group data by merge id\n",
    "    agg_data = data.groupby([merge_id]).agg(lambda x: list(x))\n",
    "\n",
    "    print(\"reorder\")\n",
    "    agg_data[text] = list(zip(agg_data[sentence_id], agg_data[text]))\n",
    "    agg_data['reordered_text'] = agg_data[text].apply(lambda x: reorder_text(x))\n",
    "    agg_data['group'] = agg_data.index.to_series().apply(lambda x: x.split('-')[0])\n",
    "    agg_data['merged_aspects'] = agg_data[ground_truth_aspect].apply(lambda x: merge_aspect(x))    \n",
    "\n",
    "    return agg_data \n",
    "\n",
    "def merge_post_level_aspect_sentiment_top_k(data, top_k):\n",
    "    \n",
    "    merge_id = \"merge_id\"\n",
    "    sentence_id = \"sentence_id\"\n",
    "    text = 'text'\n",
    "    group = 'group'\n",
    "    ground_truth_aspect = \"ground_truth_aspect\"\n",
    "    sentiment = \"sentiment\"\n",
    "\n",
    "    # select groups whoes frequency is on the top of k.\n",
    "    top_groups = data[group].value_counts().index[: top_k]\n",
    "    data = data[data[group].isin(top_groups)]\n",
    "\n",
    "    # group_id = merge_id + sentence_id\n",
    "    splitted_id = data['id'].str.split('-')\n",
    "    data[merge_id] = splitted_id.apply(lambda x: '-'.join(x[:-1]))\n",
    "    data[sentence_id] = splitted_id.apply(lambda x: x[-1]).astype(int)\n",
    "\n",
    "    columns = [merge_id, sentence_id, text, ground_truth_aspect, sentiment]\n",
    "    data = data[columns]\n",
    "\n",
    "    print(\"group\")\n",
    "    # group data by merge id\n",
    "    agg_data = data.groupby([merge_id]).agg(lambda x: list(x))\n",
    "\n",
    "    print(\"reorder\")\n",
    "    agg_data[text] = list(zip(agg_data[sentence_id], agg_data[text]))\n",
    "    agg_data['reordered_text'] = agg_data[text].apply(lambda x: reorder_text(x))\n",
    "    agg_data['group'] = agg_data.index.to_series().apply(lambda x: x.split('-')[0])\n",
    "    agg_data['merged_aspects'] = agg_data[ground_truth_aspect].apply(lambda x: merge_aspect(x))    \n",
    "    agg_data['merged_sentiment'] = agg_data[sentiment].apply(lambda x: merge_sentiment(x))    \n",
    "\n",
    "    return agg_data \n",
    "\n",
    "def merge_post_level_aspect_sentiment(data):\n",
    "    \n",
    "    merge_id = \"merge_id\"\n",
    "    sentence_id = \"sentence_id\"\n",
    "    text = 'text'\n",
    "    group = 'group'\n",
    "    ground_truth_aspect = \"ground_truth_aspect\"\n",
    "    sentiment = \"sentiment\"\n",
    "\n",
    "#     # select groups whoes frequency is on the top of k.\n",
    "#     top_groups = data[group].value_counts().index[: top_k]\n",
    "#     data = data[data[group].isin(top_groups)]\n",
    "\n",
    "    # group_id = merge_id + sentence_id\n",
    "    splitted_id = data['id'].str.split('-')\n",
    "    data[merge_id] = splitted_id.apply(lambda x: '-'.join(x[:-1]))\n",
    "    data[sentence_id] = splitted_id.apply(lambda x: x[-1]).astype(int)\n",
    "\n",
    "    columns = [merge_id, sentence_id, text, ground_truth_aspect, sentiment]\n",
    "    data = data[columns]\n",
    "\n",
    "    print(\"group\")\n",
    "    # group data by merge id\n",
    "    agg_data = data.groupby([merge_id]).agg(lambda x: list(x))\n",
    "\n",
    "    print(\"reorder\")\n",
    "    agg_data[text] = list(zip(agg_data[sentence_id], agg_data[text]))\n",
    "    agg_data['reordered_text'] = agg_data[text].apply(lambda x: reorder_text(x))\n",
    "    agg_data['group'] = agg_data.index.to_series().apply(lambda x: x.split('-')[0])\n",
    "    agg_data['merged_aspects'] = agg_data[ground_truth_aspect].apply(lambda x: merge_aspect(x))    \n",
    "    agg_data['merged_sentiment'] = agg_data[sentiment].apply(lambda x: merge_sentiment(x))    \n",
    "\n",
    "    return agg_data \n",
    "\n",
    "def process(x):\n",
    "    ans = set()\n",
    "    for each in x[1:-1].split(','): \n",
    "        words = each.strip().strip(\"'|\\\"\")\n",
    "        m = re.match('(\\w+)-', words)\n",
    "        if m is not None:\n",
    "            ans.add(m[1])\n",
    "        else:\n",
    "            ans.add(words)\n",
    "    return list(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_fn = \"../../data/lower/medical_sieve_training_set_merged.xlsx\"\n",
    "# test_fn = \"../../data/lower/medical_sieve_test_set_merged.xlsx\"\n",
    "\n",
    "\n",
    "# train_data = read_sample(train_fn)\n",
    "# test_data = read_sample(test_fn)\n",
    "\n",
    "# cols = ['ground_truth_aspect', 'group', 'text', 'id']\n",
    "\n",
    "# train_data = train_data[cols]\n",
    "# test_data = test_data[cols]\n",
    "\n",
    "# train_data = pd.concat([train_data, test_data], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhengcao/anaconda3/envs/csci566/lib/python3.6/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "def read_from_bert_prediction():\n",
    "#     fn = \"../../data/bert_prediction/5label_pred.csv\"\n",
    "    fn = \"../../data/bert_prediction/whole_5label+sentiment.csv\"\n",
    "    data = pd.read_csv(fn, index_col=0)\n",
    "    data.rename(columns={\"['pred']\": \"ground_truth_aspect\"}, inplace=True)\n",
    "    data.rename(columns={\"['1']\": \"sentiment\"}, inplace=True)    \n",
    "    return data\n",
    "\n",
    "train_data = read_from_bert_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aspect</th>\n",
       "      <th>course_of_problem</th>\n",
       "      <th>group</th>\n",
       "      <th>id</th>\n",
       "      <th>test</th>\n",
       "      <th>text</th>\n",
       "      <th>trainOrtest</th>\n",
       "      <th>treatment</th>\n",
       "      <th>ground_truth_aspect</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Ankle_Problems</td>\n",
       "      <td>Ankle_Problems-656172-3-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>What I find weird is , even with no pain I am ...</td>\n",
       "      <td>test</td>\n",
       "      <td>[]</td>\n",
       "      <td>['not about']</td>\n",
       "      <td>['0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Ankle_Problems</td>\n",
       "      <td>Ankle_Problems-656172-3-2</td>\n",
       "      <td>[]</td>\n",
       "      <td>I guess it will take awhile and more practice ...</td>\n",
       "      <td>test</td>\n",
       "      <td>[]</td>\n",
       "      <td>['not about']</td>\n",
       "      <td>['0']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  aspect course_of_problem           group                         id test  \\\n",
       "0     []                []  Ankle_Problems  Ankle_Problems-656172-3-1   []   \n",
       "1     []                []  Ankle_Problems  Ankle_Problems-656172-3-2   []   \n",
       "\n",
       "                                                text trainOrtest treatment  \\\n",
       "0  What I find weird is , even with no pain I am ...        test        []   \n",
       "1  I guess it will take awhile and more practice ...        test        []   \n",
       "\n",
       "  ground_truth_aspect sentiment  \n",
       "0       ['not about']     ['0']  \n",
       "1       ['not about']     ['0']  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert string to list\n",
    "train_data[\"ground_truth_aspect\"] = train_data[\"ground_truth_aspect\"].apply(lambda x: process(x))\n",
    "train_data[\"sentiment\"] = train_data[\"sentiment\"].apply(lambda x: process(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aspect</th>\n",
       "      <th>course_of_problem</th>\n",
       "      <th>group</th>\n",
       "      <th>id</th>\n",
       "      <th>test</th>\n",
       "      <th>text</th>\n",
       "      <th>trainOrtest</th>\n",
       "      <th>treatment</th>\n",
       "      <th>ground_truth_aspect</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Ankle_Problems</td>\n",
       "      <td>Ankle_Problems-656172-3-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>What I find weird is , even with no pain I am ...</td>\n",
       "      <td>test</td>\n",
       "      <td>[]</td>\n",
       "      <td>[not about]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Ankle_Problems</td>\n",
       "      <td>Ankle_Problems-656172-3-2</td>\n",
       "      <td>[]</td>\n",
       "      <td>I guess it will take awhile and more practice ...</td>\n",
       "      <td>test</td>\n",
       "      <td>[]</td>\n",
       "      <td>[not about]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  aspect course_of_problem           group                         id test  \\\n",
       "0     []                []  Ankle_Problems  Ankle_Problems-656172-3-1   []   \n",
       "1     []                []  Ankle_Problems  Ankle_Problems-656172-3-2   []   \n",
       "\n",
       "                                                text trainOrtest treatment  \\\n",
       "0  What I find weird is , even with no pain I am ...        test        []   \n",
       "1  I guess it will take awhile and more practice ...        test        []   \n",
       "\n",
       "  ground_truth_aspect sentiment  \n",
       "0         [not about]       [0]  \n",
       "1         [not about]       [0]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group\n",
      "reorder\n",
      "elapsed:  610.92222905159\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# merged_data = merge_post_level_aspect_sentiment_top_k(train_data, 10)\n",
    "merged_data = merge_post_level_aspect_sentiment(train_data)\n",
    "print(\"elapsed: \", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>text</th>\n",
       "      <th>ground_truth_aspect</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>reordered_text</th>\n",
       "      <th>group</th>\n",
       "      <th>merged_aspects</th>\n",
       "      <th>merged_sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merge_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACE_Inhibitors--11362-0</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6]</td>\n",
       "      <td>([1, 2, 3, 4, 5, 6], [Hi - I have just this mo...</td>\n",
       "      <td>[[not about], [not about], [not about], [not a...</td>\n",
       "      <td>[[0], [1], [0], [0], [0], [0]]</td>\n",
       "      <td>Hi - I have just this morning taken my first d...</td>\n",
       "      <td>ACE_Inhibitors</td>\n",
       "      <td>[not about]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACE_Inhibitors--11362-1</th>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>([1, 2, 3, 4], [I am in the same position as y...</td>\n",
       "      <td>[[not about], [not about], [not about], [not a...</td>\n",
       "      <td>[[0], [0], [0], [0]]</td>\n",
       "      <td>I am in the same position as you , I have Atri...</td>\n",
       "      <td>ACE_Inhibitors</td>\n",
       "      <td>[not about]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                sentence_id  \\\n",
       "merge_id                                      \n",
       "ACE_Inhibitors--11362-0  [1, 2, 3, 4, 5, 6]   \n",
       "ACE_Inhibitors--11362-1        [1, 2, 3, 4]   \n",
       "\n",
       "                                                                      text  \\\n",
       "merge_id                                                                     \n",
       "ACE_Inhibitors--11362-0  ([1, 2, 3, 4, 5, 6], [Hi - I have just this mo...   \n",
       "ACE_Inhibitors--11362-1  ([1, 2, 3, 4], [I am in the same position as y...   \n",
       "\n",
       "                                                       ground_truth_aspect  \\\n",
       "merge_id                                                                     \n",
       "ACE_Inhibitors--11362-0  [[not about], [not about], [not about], [not a...   \n",
       "ACE_Inhibitors--11362-1  [[not about], [not about], [not about], [not a...   \n",
       "\n",
       "                                              sentiment  \\\n",
       "merge_id                                                  \n",
       "ACE_Inhibitors--11362-0  [[0], [1], [0], [0], [0], [0]]   \n",
       "ACE_Inhibitors--11362-1            [[0], [0], [0], [0]]   \n",
       "\n",
       "                                                            reordered_text  \\\n",
       "merge_id                                                                     \n",
       "ACE_Inhibitors--11362-0  Hi - I have just this morning taken my first d...   \n",
       "ACE_Inhibitors--11362-1  I am in the same position as you , I have Atri...   \n",
       "\n",
       "                                  group merged_aspects  merged_sentiment  \n",
       "merge_id                                                                  \n",
       "ACE_Inhibitors--11362-0  ACE_Inhibitors    [not about]                 1  \n",
       "ACE_Inhibitors--11362-1  ACE_Inhibitors    [not about]                 0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encod Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhengcao/anaconda3/envs/csci566/lib/python3.6/site-packages/sklearn/preprocessing/label.py:951: UserWarning: unknown class(es) ['not about'] will be ignored\n",
      "  .format(sorted(unknown, key=str)))\n"
     ]
    }
   ],
   "source": [
    "def encode_label(multilabels, classes):    \n",
    "    binarizer = MultiLabelBinarizer(classes=classes)\n",
    "    encoded_labels = binarizer.fit_transform(multilabels)    \n",
    "    return encoded_labels, binarizer.classes_, binarizer\n",
    "\n",
    "labels = ['access', 'costs', 'delays', 'errors', 'trusts'] \n",
    "encoded_labels, classes, binarizer = encode_label(merged_data['merged_aspects'], labels)  \n",
    "\n",
    "merged_data['merged_aspects'] = binarizer.inverse_transform(encoded_labels)\n",
    "merged_data['merged_aspects'] = merged_data['merged_aspects'].apply(lambda x: list(x))\n",
    "\n",
    "encoded_labels = pd.DataFrame(encoded_labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_labels.set_index(merged_data.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of multi aspect:  29372\n"
     ]
    }
   ],
   "source": [
    "print(\"# of multi aspect: \", np.sum(np.sum(encoded_labels.values, axis=1) > 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>text</th>\n",
       "      <th>ground_truth_aspect</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>reordered_text</th>\n",
       "      <th>group</th>\n",
       "      <th>merged_aspects</th>\n",
       "      <th>merged_sentiment</th>\n",
       "      <th>access</th>\n",
       "      <th>costs</th>\n",
       "      <th>delays</th>\n",
       "      <th>errors</th>\n",
       "      <th>trusts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merge_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACE_Inhibitors--11362-0</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6]</td>\n",
       "      <td>([1, 2, 3, 4, 5, 6], [Hi - I have just this mo...</td>\n",
       "      <td>[[not about], [not about], [not about], [not a...</td>\n",
       "      <td>[[0], [1], [0], [0], [0], [0]]</td>\n",
       "      <td>Hi - I have just this morning taken my first d...</td>\n",
       "      <td>ACE_Inhibitors</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACE_Inhibitors--11362-1</th>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>([1, 2, 3, 4], [I am in the same position as y...</td>\n",
       "      <td>[[not about], [not about], [not about], [not a...</td>\n",
       "      <td>[[0], [0], [0], [0]]</td>\n",
       "      <td>I am in the same position as you , I have Atri...</td>\n",
       "      <td>ACE_Inhibitors</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                sentence_id  \\\n",
       "merge_id                                      \n",
       "ACE_Inhibitors--11362-0  [1, 2, 3, 4, 5, 6]   \n",
       "ACE_Inhibitors--11362-1        [1, 2, 3, 4]   \n",
       "\n",
       "                                                                      text  \\\n",
       "merge_id                                                                     \n",
       "ACE_Inhibitors--11362-0  ([1, 2, 3, 4, 5, 6], [Hi - I have just this mo...   \n",
       "ACE_Inhibitors--11362-1  ([1, 2, 3, 4], [I am in the same position as y...   \n",
       "\n",
       "                                                       ground_truth_aspect  \\\n",
       "merge_id                                                                     \n",
       "ACE_Inhibitors--11362-0  [[not about], [not about], [not about], [not a...   \n",
       "ACE_Inhibitors--11362-1  [[not about], [not about], [not about], [not a...   \n",
       "\n",
       "                                              sentiment  \\\n",
       "merge_id                                                  \n",
       "ACE_Inhibitors--11362-0  [[0], [1], [0], [0], [0], [0]]   \n",
       "ACE_Inhibitors--11362-1            [[0], [0], [0], [0]]   \n",
       "\n",
       "                                                            reordered_text  \\\n",
       "merge_id                                                                     \n",
       "ACE_Inhibitors--11362-0  Hi - I have just this morning taken my first d...   \n",
       "ACE_Inhibitors--11362-1  I am in the same position as you , I have Atri...   \n",
       "\n",
       "                                  group merged_aspects  merged_sentiment  \\\n",
       "merge_id                                                                   \n",
       "ACE_Inhibitors--11362-0  ACE_Inhibitors             []                 1   \n",
       "ACE_Inhibitors--11362-1  ACE_Inhibitors             []                 0   \n",
       "\n",
       "                         access  costs  delays  errors  trusts  \n",
       "merge_id                                                        \n",
       "ACE_Inhibitors--11362-0       0      0       0       0       0  \n",
       "ACE_Inhibitors--11362-1       0      0       0       0       0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data = pd.concat([merged_data, encoded_labels], axis=1)\n",
    "output_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                     0.849702\n",
       "trusts                               0.045536\n",
       "delays                               0.030032\n",
       "errors                               0.027767\n",
       "costs                                0.012561\n",
       "access                               0.012077\n",
       "errors,trusts                        0.004808\n",
       "delays,trusts                        0.003392\n",
       "access,trusts                        0.002279\n",
       "delays,errors                        0.002240\n",
       "costs,trusts                         0.001969\n",
       "access,delays                        0.001201\n",
       "access,errors                        0.000929\n",
       "costs,errors                         0.000876\n",
       "costs,delays                         0.000784\n",
       "access,costs                         0.000781\n",
       "delays,errors,trusts                 0.000610\n",
       "access,errors,trusts                 0.000413\n",
       "costs,errors,trusts                  0.000356\n",
       "access,delays,trusts                 0.000350\n",
       "access,costs,trusts                  0.000290\n",
       "costs,delays,trusts                  0.000236\n",
       "access,delays,errors                 0.000172\n",
       "costs,delays,errors                  0.000108\n",
       "access,costs,delays                  0.000097\n",
       "access,delays,errors,trusts          0.000093\n",
       "access,costs,errors                  0.000087\n",
       "costs,delays,errors,trusts           0.000078\n",
       "access,costs,errors,trusts           0.000077\n",
       "access,costs,delays,trusts           0.000046\n",
       "access,costs,delays,errors,trusts    0.000027\n",
       "access,costs,delays,errors           0.000024\n",
       "Name: merged_aspects, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = output_data['merged_aspects'].apply(lambda x: ','.join(sorted(x))).value_counts() \n",
    "a / np.sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_in_format_1(merged_data_fn, merged_data, index):\n",
    "    merged_data_copy = merged_data.copy()\n",
    "    columns = [\"reordered_text\"]\n",
    "    merged_data_copy[\"reordered_text\"] = merged_data_copy[\"reordered_text\"].apply(lambda x: x.lower())\n",
    "    merged_data_copy[columns].to_csv(merged_data_fn, sep=\"\\t\", header=False, index=index)    \n",
    "    \n",
    "def write_in_format_meta(merged_data_fn, merged_data, index):\n",
    "    columns = [\"group\", \"reordered_text\", \"merged_aspects\", \"access\", \"costs\", \"delays\", \"errors\", \"trusts\", \"merged_sentiment\"]\n",
    "    merged_data[columns].to_csv(merged_data_fn, sep=\"\\t\", index=index)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing in format meta\n"
     ]
    }
   ],
   "source": [
    "print(\"writing in format meta\")\n",
    "write_in_format_meta(\"../../data/bert_prediction/whole_corpus_meta.csv\", output_data, True)\n",
    "write_in_format_1(\"../../data/bert_prediction/whole_corpus.csv\", output_data, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sample data\n",
    "\n",
    "sample data based on weights of each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "meta = pd.read_csv(\"../../data/bert_prediction/whole_corpus_meta.csv\", sep='\\t')\n",
    "\n",
    "# print(meta.columns)\n",
    "train_meta, test_meta = train_test_split(meta, test_size=0.1, stratify=meta['group'], random_state=42)\n",
    "test_meta = test_meta.set_index('merge_id')\n",
    "# test_meta.head(5)\n",
    "write_in_format_1(\"../../data/bert_prediction/whole_corpus_tiny.csv\", test_meta, False)\n",
    "write_in_format_meta(\"../../data/bert_prediction/whole_corpus_meta_tiny.csv\", test_meta, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv(\"../../data/bert_prediction/whole_corpus_meta.csv\", sep='\\t')\n",
    "\n",
    "cols = ['Abdominal_Disorders', 'Cataract', 'Gallbladder_Problems', 'Irritable_Bowel_Syndrome', 'Prostate_Problems']\n",
    "meta = meta[meta.group.isin(cols)]\n",
    "\n",
    "# print(meta.columns)\n",
    "train_meta, test_meta = train_test_split(meta, test_size=0.5, stratify=meta['group'], random_state=42)\n",
    "test_meta = test_meta.set_index('merge_id')\n",
    "\n",
    "write_in_format_1(\"../../data/bert_prediction/whole_corpus_top_5_viz.csv\", test_meta, False)\n",
    "write_in_format_meta(\"../../data/bert_prediction/whole_corpus_meta_top_5_viz.csv\", test_meta, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52951, 9)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_meta.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
