{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from random import randrange, sample, seed\n",
    "seed(1)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isDelays(sentence):\n",
    "    if len(sentence) < 100 and ('?' in sentence or ' if ' in sentence):\n",
    "        return False\n",
    "    if ' wait ' in sentence \\\n",
    "    or ' delay ' in sentence \\\n",
    "    or ' slow ' in sentence \\\n",
    "    or ' for so long ' in sentence \\\n",
    "    or ' be so long ' in sentence \\\n",
    "    or ' take so long ' in sentence \\\n",
    "    or ' long time ' in sentence \\\n",
    "    or ' longer ' in sentence \\\n",
    "    or ' postpone ' in sentence \\\n",
    "    or ' reschedule ' in sentence \\\n",
    "    or ' numerous time' in sentence \\\n",
    "    or ' quicker ' in sentence \\\n",
    "    or '  take forever' in sentence \\\n",
    "    or ' prolong ' in sentence:\n",
    "        return True\n",
    "    if (' ridiculous ' in sentence \n",
    "        or ' unacceptable 'in sentence) and \\\n",
    "    ('months' in sentence \\\n",
    "     or 'days' in sentence \\\n",
    "     or 'weeks' in sentence \\\n",
    "     or 'hours' in sentence \\\n",
    "     or 'years' in sentence \\\n",
    "     or 'month' in sentence \\\n",
    "     or 'day' in sentence \\\n",
    "     or 'week' in sentence \\\n",
    "     or 'hour' in sentence \\\n",
    "     or 'year' in sentence):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def isCosts(sentence):\n",
    "    if len(sentence) < 100 and ('?' in sentence or ' if ' in sentence):\n",
    "        return False\n",
    "    if ' cost ' in sentence \\\n",
    "    or ' costly ' in sentence \\\n",
    "    or ' pay for ' in sentence \\\n",
    "    or 'payment' in sentence \\\n",
    "    or 'afford' in sentence \\\n",
    "    or 'expensive' in sentence \\\n",
    "    or 'cheap' in sentence \\\n",
    "    or ' money ' in sentence \\\n",
    "    or 'limit' in sentence \\\n",
    "    or ' overprice ' in sentence \\\n",
    "    or ' price' in sentence \\\n",
    "    or ' copay' in sentence \\\n",
    "    or ' bill ' in sentence \\\n",
    "    or ' co-pay ' in sentence \\\n",
    "    or ' fee ' in sentence \\\n",
    "    or ' charge ' in sentence \\\n",
    "    or ' deductible ' in sentence \\\n",
    "    or ' premium ' in sentence \\\n",
    "    or 'out-of-network' in sentence \\\n",
    "    or 'out of network' in sentence \\\n",
    "    or 'in-network' in sentence \\\n",
    "    or 'in network' in sentence:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def isAccess(sentence):\n",
    "    if len(sentence) < 100 and ('?' in sentence or ' if ' in sentence):\n",
    "        return False\n",
    "    if ' access to ' in sentence \\\n",
    "    or ' be refuse ' in sentence \\\n",
    "    or ' accept new patient ' in sentence \\\n",
    "    or ' be cancel ' in sentence \\\n",
    "    or 'consultation' in sentence \\\n",
    "    or 'registration' in sentence \\\n",
    "    or 'shortage' in sentence \\\n",
    "    or ' crowd ' in sentence \\\n",
    "    or ' reschedule ' in sentence \\\n",
    "    or 'cancellation' in sentence \\\n",
    "    or ' ward ' in sentence \\\n",
    "    or 'available' in sentence \\\n",
    "    or 'reject' in sentence \\\n",
    "    or 'to service' in sentence \\\n",
    "    or 'admission' in sentence \\\n",
    "    or 'out-of-network' in sentence \\\n",
    "    or 'out of network' in sentence \\\n",
    "    or 'in-network' in sentence \\\n",
    "    or 'in network' in sentence \\\n",
    "    or 'limitation' in sentence \\\n",
    "    or ' nearby hospital' in sentence \\\n",
    "    or ' nearby clinic ' in sentence:\n",
    "        return True\n",
    "    if ' limit ' in sentence \\\n",
    "    and 'access' in sentence:\n",
    "        return True\n",
    "    if ' treat' in sentence \\\n",
    "    and ' refus' in sentence:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "     \n",
    "def isErrors(sentence):\n",
    "    if len(sentence) < 100 and ('?' in sentence or ' if ' in sentence):\n",
    "        return False\n",
    "    if ' inept ' in sentence and 'doctor' in sentence:\n",
    "        return True\n",
    "    if 'miss diagnosis' in sentence \\\n",
    "    or 'mis-diagnosis' in sentence \\\n",
    "    or 'misdiagnose' in sentence \\\n",
    "    or 'misdiagnosis' in sentence \\\n",
    "    or 'clerical' in sentence \\\n",
    "    or 'erroneous' in sentence \\\n",
    "    or 'wrong disease' in sentence \\\n",
    "    or 'typo' in sentence \\\n",
    "    or 'wrong medi' in sentence \\\n",
    "    or 'medical accident' in sentence \\\n",
    "    or 'incorrect' in sentence \\\n",
    "    or 'inconclusive' in sentence \\\n",
    "    or 'fault' in sentence \\\n",
    "    or 'mislead' in sentence \\\n",
    "    or 'examination' in sentence \\\n",
    "    or 'incompetent' in sentence \\\n",
    "    or 'inept' in sentence \\\n",
    "    or 'judgement' in sentence \\\n",
    "    or 'judgment' in sentence \\\n",
    "    or 'miss' in sentence:\n",
    "        return True\n",
    "    if ('make' and 'mistake' in sentence) \\\n",
    "    or ' be a mistake' in sentence:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def isTreatments(sentence):\n",
    "    if len(sentence) < 100 and ('?' in sentence or ' if ' in sentence):\n",
    "        return False\n",
    "    if ' get better ' in sentence \\\n",
    "    and ' you ' not in sentence \\\n",
    "    and ' hope' not in sentence \\\n",
    "    and ' life ' not in sentence \\\n",
    "    and ' will ' not in sentence \\\n",
    "    and '?' not in sentence \\\n",
    "    and ' if ' not in sentence \\\n",
    "    and ' to get better ' not in sentence \\\n",
    "    and ' can get better ' not in sentence \\\n",
    "    and ' it ll ' not in sentence \\\n",
    "    and ' i ' in sentence:\n",
    "        return True\n",
    "    if ' feel better ' in sentence \\\n",
    "    and ' you ' not in sentence \\\n",
    "    and ' hope' not in sentence \\\n",
    "    and ' will ' not in sentence \\\n",
    "    and '?' not in sentence \\\n",
    "    and ' if ' not in sentence \\\n",
    "    and ' can feel better ' not in sentence \\\n",
    "    and ' would ' not in sentence \\\n",
    "    and ' should feel better' not in sentence \\\n",
    "    and ' i ' in sentence:\n",
    "        return True\n",
    "    if ' get worse ' in sentence \\\n",
    "    and ' you ' not in sentence \\\n",
    "    and ' hope' not in sentence \\\n",
    "    and ' life ' not in sentence \\\n",
    "    and ' will ' not in sentence \\\n",
    "    and '?' not in sentence \\\n",
    "    and ' if ' not in sentence \\\n",
    "    and ' to get worse ' not in sentence \\\n",
    "    and ' can get worse ' not in sentence \\\n",
    "    and ' it ll ' not in sentence \\\n",
    "    and ' i ' in sentence:\n",
    "        return True\n",
    "    if ' feel worse ' in sentence \\\n",
    "    and ' you ' not in sentence \\\n",
    "    and ' hope' not in sentence \\\n",
    "    and ' will ' not in sentence \\\n",
    "    and '?' not in sentence \\\n",
    "    and ' if ' not in sentence \\\n",
    "    and ' can feel worse ' not in sentence \\\n",
    "    and ' would ' not in sentence \\\n",
    "    and ' should feel worse ' not in sentence \\\n",
    "    and ' i ' in sentence:\n",
    "        return True\n",
    "\n",
    "    if ' treatment ' in sentence \\\n",
    "    and ' hope' not in sentence:\n",
    "        return True\n",
    "\n",
    "    if ' be never end ' in sentence \\\n",
    "    or ' relapse ' in sentence \\\n",
    "    or ' still sick' in sentence \\\n",
    "    or ' still ill' in sentence \\\n",
    "    or ' recurrent ' in sentence \\\n",
    "    or ' constant pain ' in sentence \\\n",
    "    or ' be cure ' in sentence \\\n",
    "    or ' assessment ' in sentence \\\n",
    "    or ' rehabilitation ' in sentence \\\n",
    "    or ' good therapy ' in sentence \\\n",
    "    or ' great therapy ' in sentence \\\n",
    "    or ' excellent therapy ' in sentence \\\n",
    "    or ' prognosis ' in sentence \\\n",
    "    or (' therapy '  in sentence and ' not work '  in sentence):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "def isStaffAndTrust(sentence):\n",
    "    if len(sentence) < 100 and ('?' in sentence or ' if ' in sentence):\n",
    "        return False\n",
    "    # staff attitude and patient trust\n",
    "    if 'manager' in sentence \\\n",
    "    or 'staff' in sentence \\\n",
    "    or ' nurse' in sentence \\\n",
    "    or 'therapist' in sentence \\\n",
    "    or 'attitude' in sentence \\\n",
    "    or 'unethical' in sentence \\\n",
    "    or 'ethical' in sentence \\\n",
    "    or ' be care' in sentence \\\n",
    "    or 'uncaring' in sentence \\\n",
    "    or 'obnoxious' in sentence \\\n",
    "    or 'lovely' in sentence \\\n",
    "    or 'dismissive' in sentence \\\n",
    "    or ' so kind' in sentence \\\n",
    "    or 'cruel' in sentence \\\n",
    "    or 'disrespectful' in sentence \\\n",
    "    or ' respectful ' in sentence \\\n",
    "    or ' empathetic ' in sentence \\\n",
    "    or ' empathy ' in sentence \\\n",
    "    or ' sympathy ' in sentence \\\n",
    "    or 'sympathetic' in sentence \\\n",
    "    or ' trust' in sentence \\\n",
    "    or 'lack of concern' in sentence \\\n",
    "    or ' rude' in sentence \\\n",
    "    or ' dismiss me' in sentence \\\n",
    "    or 'lack of respect' in sentence \\\n",
    "    or 'polite' in sentence \\\n",
    "    or ' uncaring ' in sentence \\\n",
    "    or ' manner' in sentence \\\n",
    "    or 'so mean' in sentence \\\n",
    "    or 'aggressive' in sentence \\\n",
    "    or 'insensitive' in sentence \\\n",
    "    or 'neglect' in sentence \\\n",
    "    or 'lack of understand' in sentence \\\n",
    "    or 'confidence' in sentence \\\n",
    "    or 'privacy' in sentence:\n",
    "        return True\n",
    "    if ' be understand ' in sentence \\\n",
    "    and 'husband' not in sentence \\\n",
    "    and 'wife' not in sentence \\\n",
    "    and 'employer' not in sentence \\\n",
    "    and 'boyfriend' not in sentence \\\n",
    "    and 'girlfriend' not in sentence \\\n",
    "    and 'i be understand' not in sentence \\\n",
    "    and 'family' not in sentence:\n",
    "        return True\n",
    "\n",
    "    # staff’s professional skills and conduct\n",
    "    if ' skill' in sentence \\\n",
    "    or 'treat well' in sentence \\\n",
    "    or 'treat bad' in sentence \\\n",
    "    or 'unclear' in sentence \\\n",
    "    or ' good treat ' in sentence \\\n",
    "    or ' great treat ' in sentence \\\n",
    "    or ' poor treat ' in sentence \\\n",
    "    or ' bad treat ' in sentence \\\n",
    "    or ' worst treat ' in sentence \\\n",
    "    or ' good care' in sentence \\\n",
    "    or ' great care' in sentence \\\n",
    "     or ' excellent care' in sentence \\\n",
    "    or ' poor care' in sentence \\\n",
    "    or ' bad care' in sentence \\\n",
    "    or ' inept ' in sentence \\\n",
    "    or 'poor communication' in sentence \\\n",
    "    or ' expertise' in sentence \\\n",
    "    or 'fob off' in sentence \\\n",
    "    or 'helpful' in sentence \\\n",
    "    or 'unprofessional' in sentence \\\n",
    "    or 'shout at' in sentence \\\n",
    "    or 'irresponsible' in sentence \\\n",
    "    or 'unqualified' in sentence \\\n",
    "    or 'qualify' in sentence \\\n",
    "    or 'lack of train' in sentence \\\n",
    "    or 'no train' in sentence \\\n",
    "    or 'incapable' in sentence \\\n",
    "    or 'unwilling' in sentence \\\n",
    "    or 'corrupt' in sentence \\\n",
    "    or 'ignore' in sentence \\\n",
    "    or 'mislead' in sentence \\\n",
    "    or 'lack of knowledge' in sentence \\\n",
    "    or ' bad behavi' in sentence \\\n",
    "    or 'not listen' in sentence \\\n",
    "    or 'inappropriate' in sentence \\\n",
    "    or 'dedicate' in sentence \\\n",
    "    or 'very professional' in sentence \\\n",
    "    or 'so professional' in sentence:\n",
    "        return True\n",
    "    if ' look after me' in sentence \\\n",
    "    and 'friend' not in sentence \\\n",
    "    and 'husband' not in sentence \\\n",
    "    and 'wife' not in sentence:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def hasCourse(sentence, cou_realtions):\n",
    "    if len(cou_realtions) > 0 \\\n",
    "    and 'hope' not in sentence \\\n",
    "    and '?' not in sentence \\\n",
    "    and ' will ' not in sentence \\\n",
    "    and ' if ' not in sentence \\\n",
    "    and ' you ' not in sentence:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def processForRules(sen):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    new_sen = \"\"\n",
    "    for word in sen.lower().split():\n",
    "        new_word = lemmatizer.lemmatize(word, pos='v')\n",
    "        new_word = lemmatizer.lemmatize(new_word, pos='n')\n",
    "        new_sen += ' ' + new_word\n",
    "    return new_sen[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseSentense(lines, root, text):\n",
    "    sen_index = []\n",
    "    treatment_index = []\n",
    "    test_index = []\n",
    "    cou_of_index = []\n",
    "    sentence_split = []\n",
    "    treatments = []\n",
    "    tests = []\n",
    "    cou_of = []\n",
    "    for line in lines:\n",
    "        if line[:11] == 'NamedEntity' and line[31:40] == 'treatment':\n",
    "            treatment_index.append([int(line.split(\"\\t\")[1]), int(line.split(\"\\t\")[2]), line.split(\"\\t\")[7][3:].strip()])\n",
    "        if line[:11] == 'NamedEntity' and line[31:35] == 'test':\n",
    "            test_index.append([int(line.split(\"\\t\")[1]), int(line.split(\"\\t\")[2]), line.strip().split(\"\\t\")[7][3:].strip()])\n",
    "        if line[:8] == 'Sentence':\n",
    "            sen_index.append([int(line.split(\"\\t\")[1]), int(line.split(\"\\t\")[2])])\n",
    "    \n",
    "    entity_dict = {}\n",
    "    for child in root:\n",
    "        if 'ClampNameEntityUIMA' in child.tag and child.attrib['semanticTag'] in set([\"COU\", \"problem\"]):\n",
    "            entity_dict[child.attrib['{http://www.omg.org/XMI}id']] = {\"begin-end\": (int(child.attrib['begin']), int(child.attrib['end'])), \"Semantic\": child.attrib['semanticTag']}\n",
    "            \n",
    "        if 'ClampRelationUIMA' in child.tag and child.attrib['semanticTag'] == \"COU_Of\":\n",
    "            cou_of_index.append((entity_dict[child.attrib['entTo']][\"begin-end\"][0],\n",
    "                                entity_dict[child.attrib['entTo']][\"begin-end\"][1], \n",
    "                                entity_dict[child.attrib['entFrom']][\"begin-end\"][0],\n",
    "                                entity_dict[child.attrib['entFrom']][\"begin-end\"][1]))\n",
    "    for index in sen_index:\n",
    "        sentence_split.append(text[index[0]:index[1]])\n",
    "        treatment = []\n",
    "        for t_index in treatment_index:\n",
    "            if t_index[0] >= index[0] and t_index[1] <= index[1]:\n",
    "                treatment.append(t_index[2])\n",
    "        treatments.append(treatment)\n",
    "                                \n",
    "        test = []\n",
    "        for te_index in test_index:\n",
    "            if te_index[0] >= index[0] and te_index[1] <= index[1]:\n",
    "                test.append(te_index[2])\n",
    "        tests.append(test)\n",
    "        \n",
    "        cou = []\n",
    "        for cou_index in cou_of_index:\n",
    "            if cou_index[0] >= index[0] \\\n",
    "            and cou_index[1] <= index[1] \\\n",
    "            and cou_index[2] >= index[0] \\\n",
    "            and cou_index[3] <= index[1]:\n",
    "                cou.append(text[cou_index[0]:cou_index[1]] + '->' + text[cou_index[2]:cou_index[3]])\n",
    "        cou_of.append(cou)\n",
    "    return (sentence_split, treatments, tests, cou_of)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "B\n",
      "C\n",
      "D\n",
      "E\n",
      "F\n",
      "G\n",
      "H\n",
      "I\n",
      "K\n",
      "L\n",
      "M\n",
      "N\n",
      "O\n",
      "P\n",
      "Q\n",
      "R\n",
      "S\n",
      "T\n",
      "U\n",
      "V\n",
      "W\n"
     ]
    }
   ],
   "source": [
    "raw_text_path = \"/Users/jaden/ClampCmd_1.6.0/input\"\n",
    "entity_annotation_path = \"/Users/jaden/ClampCmd_1.6.0/output\"\n",
    "sentense_dic  = []\n",
    "countforannotation = {'isDelays': 0, 'isCosts': 0, 'isAccess': 0, 'isErrors': 0, 'isTreatments': 0, 'isStaffAndTrust': 0}\n",
    "\n",
    "for files in sorted(os.listdir(raw_text_path)):\n",
    "    if '.' not in files:\n",
    "        print(files)\n",
    "        for filename in os.listdir(raw_text_path + '/' + files):\n",
    "            if filename[-4:] == \".txt\":\n",
    "                text_f = open(raw_text_path + '/' + files + '/' + filename, 'r')\n",
    "                endIndex = re.search('-',filename).span()[0]\n",
    "                group = filename[:endIndex]\n",
    "                text = text_f.readline()\n",
    "                text_f.close()\n",
    "            \n",
    "                anno_f = open(entity_annotation_path + '/' + filename[0] + \"/\" + filename, 'r')\n",
    "                tree = ET.parse(entity_annotation_path + '/' + filename[0] + \"/\" + filename[:-4] + '.xmi')\n",
    "                root = tree.getroot()\n",
    "                sentences, treatments, test, cou_realtions = parseSentense(anno_f.readlines(), root, text)\n",
    "                anno_f.close()\n",
    "                count = 0\n",
    "                for sen, treat, te, cou_realtion in zip(sentences, treatments, test, cou_realtions):\n",
    "                    count += 1\n",
    "                    trainOrtest = 'test'\n",
    "                    train_class = []\n",
    "                    processed_sen = processForRules(sen)\n",
    "                    if isDelays(processed_sen):\n",
    "                        countforannotation['isDelays'] += 1\n",
    "                        train_class.append(1)\n",
    "                        trainOrtest = 'train'\n",
    "                    if isCosts(processed_sen):\n",
    "                        countforannotation['isCosts'] += 1\n",
    "                        train_class.append(2)\n",
    "                        trainOrtest = 'train'\n",
    "                    if isAccess(processed_sen):\n",
    "                        countforannotation['isAccess'] += 1\n",
    "                        train_class.append(3)\n",
    "                        trainOrtest = 'train'\n",
    "                    if isErrors(processed_sen):\n",
    "                        countforannotation['isErrors'] += 1\n",
    "                        train_class.append(4)\n",
    "                        trainOrtest = 'train'\n",
    "                    if isTreatments(processed_sen) or hasCourse(processed_sen, cou_realtion):\n",
    "                        countforannotation['isTreatments'] += 1\n",
    "                        train_class.append(5)\n",
    "                        trainOrtest = 'train'\n",
    "                    if isStaffAndTrust(processed_sen):\n",
    "                        countforannotation['isStaffAndTrust'] += 1\n",
    "                        train_class.append(6)\n",
    "                        trainOrtest = 'train'\n",
    "                    sentense_dic.append({'group': group, 'id': filename[:-4] + '-' +str(count), 'text': sen, 'treatment': treat, 'course_of_problem': cou_realtion, 'test': te, 'trainOrtest': trainOrtest, 'aspect': train_class})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_df = pd.DataFrame(sentense_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aspect</th>\n",
       "      <th>course_of_problem</th>\n",
       "      <th>group</th>\n",
       "      <th>id</th>\n",
       "      <th>test</th>\n",
       "      <th>text</th>\n",
       "      <th>trainOrtest</th>\n",
       "      <th>treatment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Ankle_Problems</td>\n",
       "      <td>Ankle_Problems-656172-3-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>What I find weird is , even with no pain I am ...</td>\n",
       "      <td>test</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Ankle_Problems</td>\n",
       "      <td>Ankle_Problems-656172-3-2</td>\n",
       "      <td>[]</td>\n",
       "      <td>I guess it will take awhile and more practice ...</td>\n",
       "      <td>test</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[5]</td>\n",
       "      <td>[reduce-&gt;swelling]</td>\n",
       "      <td>Ankle_Problems</td>\n",
       "      <td>Ankle_Problems-656172-3-3</td>\n",
       "      <td>[]</td>\n",
       "      <td>Yeah I will continue with therapy and also usi...</td>\n",
       "      <td>train</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Anxiety_Disorders</td>\n",
       "      <td>Anxiety_Disorders-591664-1-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>I am also on it and at similar levels .</td>\n",
       "      <td>test</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Anxiety_Disorders</td>\n",
       "      <td>Anxiety_Disorders-591664-1-2</td>\n",
       "      <td>[]</td>\n",
       "      <td>My husband thinks this is what is making the d...</td>\n",
       "      <td>test</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  aspect   course_of_problem              group                            id  \\\n",
       "0     []                  []     Ankle_Problems     Ankle_Problems-656172-3-1   \n",
       "1     []                  []     Ankle_Problems     Ankle_Problems-656172-3-2   \n",
       "2    [5]  [reduce->swelling]     Ankle_Problems     Ankle_Problems-656172-3-3   \n",
       "3     []                  []  Anxiety_Disorders  Anxiety_Disorders-591664-1-1   \n",
       "4     []                  []  Anxiety_Disorders  Anxiety_Disorders-591664-1-2   \n",
       "\n",
       "  test                                               text trainOrtest  \\\n",
       "0   []  What I find weird is , even with no pain I am ...        test   \n",
       "1   []  I guess it will take awhile and more practice ...        test   \n",
       "2   []  Yeah I will continue with therapy and also usi...       train   \n",
       "3   []            I am also on it and at similar levels .        test   \n",
       "4   []  My husband thinks this is what is making the d...        test   \n",
       "\n",
       "  treatment  \n",
       "0        []  \n",
       "1        []  \n",
       "2        []  \n",
       "3        []  \n",
       "4        []  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7651255 entries, 0 to 7651254\n",
      "Data columns (total 8 columns):\n",
      "aspect               object\n",
      "course_of_problem    object\n",
      "group                object\n",
      "id                   object\n",
      "test                 object\n",
      "text                 object\n",
      "trainOrtest          object\n",
      "treatment            object\n",
      "dtypes: object(8)\n",
      "memory usage: 467.0+ MB\n"
     ]
    }
   ],
   "source": [
    "whole_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_df.to_csv('whole_data_sentence.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences to be annotaed: 601424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'isDelays': 153801,\n",
       " 'isCosts': 64082,\n",
       " 'isAccess': 29356,\n",
       " 'isErrors': 52341,\n",
       " 'isTreatments': 154615,\n",
       " 'isStaffAndTrust': 147229}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Total sentences to be annotaed:', sum(countforannotation.values()))\n",
    "countforannotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "isDelays_ = []\n",
    "isCosts_ = []\n",
    "isAccess_ = []\n",
    "isErrors_ = []\n",
    "isTreatments_ = []\n",
    "isStaffAndTrust_ = []\n",
    "for each in sentense_dic:\n",
    "    if 1 in each['aspect']:\n",
    "        isDelays_.append(each)\n",
    "    if 2 in each['aspect']:\n",
    "        isCosts_.append(each)\n",
    "    if 3 in each['aspect']:\n",
    "        isAccess_.append(each)\n",
    "    if 4 in each['aspect']:\n",
    "        isErrors_.append(each)\n",
    "    if 5 in each['aspect']:\n",
    "        isTreatments_.append(each)\n",
    "    if 6 in each['aspect']:\n",
    "        isStaffAndTrust_.append(each)\n",
    "        \n",
    "isDelays_df = pd.DataFrame(isDelays_)\n",
    "isCosts_df = pd.DataFrame(isCosts_)\n",
    "isAccess_df = pd.DataFrame(isAccess_)  \n",
    "isErrors_df = pd.DataFrame(isErrors_)  \n",
    "isTreatments_df = pd.DataFrame(isTreatments_)  \n",
    "isStaffAndTrust_df = pd.DataFrame(isStaffAndTrust_) \n",
    "\n",
    "# isDelays_df['sub_aspect'] = ''\n",
    "# isDelays_df['sentiment'] = ''\n",
    "# isCosts_df['sub_aspect'] = ''\n",
    "# isCosts_df['sentiment'] = ''\n",
    "# isAccess_df['sub_aspect'] = ''\n",
    "# isAccess_df['sentiment'] = ''\n",
    "# isErrors_df['sub_aspect'] = ''\n",
    "# isErrors_df['sentiment'] = ''\n",
    "# isTreatments_df['sub_aspect'] = ''\n",
    "# isTreatments_df['sentiment'] = ''\n",
    "# isStaffAndTrust_df['sub_aspect'] = ''\n",
    "# isStaffAndTrust_df['sentiment'] = ''\n",
    "\n",
    "isDelays_df['batch'] = [int(each / (isDelays_df.shape[0]/10)) + 1 for each in sample(range(0, isDelays_df.shape[0]), isDelays_df.shape[0])]\n",
    "isCosts_df['batch'] = [int(each / (isCosts_df.shape[0]/10)) + 1 for each in sample(range(0, isCosts_df.shape[0]), isCosts_df.shape[0])]\n",
    "isAccess_df['batch'] = [int(each / (isAccess_df.shape[0]/10)) + 1 for each in sample(range(0, isAccess_df.shape[0]), isAccess_df.shape[0])]\n",
    "isErrors_df['batch'] = [int(each / (isErrors_df.shape[0]/10)) + 1 for each in sample(range(0, isErrors_df.shape[0]), isErrors_df.shape[0])]\n",
    "isTreatments_df['batch'] = [int(each / (isTreatments_df.shape[0]/10)) + 1 for each in sample(range(0, isTreatments_df.shape[0]), isTreatments_df.shape[0])]\n",
    "isStaffAndTrust_df['batch'] = [int(each / (isStaffAndTrust_df.shape[0]/10)) + 1 for each in sample(range(0, isStaffAndTrust_df.shape[0]), isStaffAndTrust_df.shape[0])]\n",
    "\n",
    "train_path = 'train'\n",
    "os.mkdir(train_path)\n",
    "isDelays_df.to_excel(train_path + '/isDelays.xlsx', index=False)\n",
    "isCosts_df.to_excel(train_path + '/isCosts_df.xlsx', index=False)\n",
    "isAccess_df.to_excel(train_path + '/isAccess_df.xlsx', index=False)\n",
    "isErrors_df.to_excel(train_path + '/isErrors_df.xlsx', index=False)\n",
    "isTreatments_df.to_excel(train_path + '/isTreatments_df.xlsx', index=False)\n",
    "isStaffAndTrust_df.to_excel(train_path + '/isStaffAndTrust_df.xlsx', index=False)\n",
    "\n",
    "batchNum = 1\n",
    "batch_path  = 'batch' + str(batchNum)\n",
    "os.mkdir(batch_path)\n",
    "isDelays_df[isDelays_df.batch == batchNum].to_excel(batch_path +'/isDelays_batch' + str(batchNum) + '.xlsx', index=False)\n",
    "isCosts_df[isCosts_df.batch == batchNum].to_excel(batch_path +'/isCosts_batch'+ str(batchNum) + '.xlsx', index=False)\n",
    "isAccess_df[isAccess_df.batch == batchNum].to_excel(batch_path + '/isAccess_batch' + str(batchNum) + '.xlsx', index=False)\n",
    "isErrors_df[isErrors_df.batch == batchNum].to_excel(batch_path + '/isErrors_batch' + str(batchNum) + '.xlsx', index=False)\n",
    "isTreatments_df[isTreatments_df.batch == batchNum].to_excel(batch_path + '/isTreatments_batch' + str(batchNum) + '.xlsx', index=False)\n",
    "isStaffAndTrust_df[isStaffAndTrust_df.batch == batchNum].to_excel(batch_path + '/isStaffAndTrust_batch' + str(batchNum) + '.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 1000 sample for batch1\n",
    "batchNum = 1\n",
    "isDelays_df_batch1_rest, isDelays_df_batch1_1000 = train_test_split(isDelays_df[isDelays_df.batch == batchNum], test_size=1000, random_state=1)\n",
    "isCosts_df_batch1_rest, isCosts_df_batch1_1000 = train_test_split(isCosts_df[isCosts_df.batch == batchNum], test_size=1000, random_state=1)\n",
    "isAccess_df_batch1_rest, isAccess_df_batch1_1000 = train_test_split(isAccess_df[isAccess_df.batch == batchNum], test_size=1000, random_state=1)\n",
    "isErrors_df_batch1_rest, isErrors_df_batch1_1000 = train_test_split(isErrors_df[isErrors_df.batch == batchNum], test_size=1000, random_state=1)\n",
    "isTreatments_df_batch1_rest, isTreatments_df_batch1_1000 = train_test_split(isTreatments_df[isTreatments_df.batch == batchNum], test_size=1000, random_state=1)\n",
    "isStaffAndTrust_df_batch1_rest, isStaffAndTrust_df_batch1_1000 = train_test_split(isStaffAndTrust_df[isStaffAndTrust_df.batch == batchNum], test_size=1000, random_state=1)\n",
    "\n",
    "batch_path1000  = batch_path + '/batch1_1000' \n",
    "os.mkdir(batch_path1000)\n",
    "isDelays_df_batch1_1000.to_excel(batch_path1000 + '/isDelays_batch1_1000.xlsx', index=False)\n",
    "isCosts_df_batch1_1000.to_excel(batch_path1000 + '/isCosts_batch1_1000.xlsx', index=False)\n",
    "isAccess_df_batch1_1000.to_excel(batch_path1000 +'/isAccess_batch1_1000.xlsx', index=False)\n",
    "isErrors_df_batch1_1000.to_excel(batch_path1000 + '/isErrors_batch1_1000.xlsx', index=False)\n",
    "isTreatments_df_batch1_1000.to_excel(batch_path1000 + '/isTreatments_batch1_1000.xlsx', index=False)\n",
    "isStaffAndTrust_df_batch1_1000.to_excel(batch_path1000 + '/isStaffAndTrust_batch1_1000.xlsx', index=False)\n",
    "\n",
    "batch_pathRest = batch_path + '/batch1_rest'\n",
    "os.mkdir(batch_pathRest)\n",
    "isDelays_df_batch1_rest.to_excel(batch_pathRest + '/isDelays_batch1_rest.xlsx', index=False)\n",
    "isCosts_df_batch1_rest.to_excel(batch_pathRest + '/isCosts_batch1_rest.xlsx', index=False)\n",
    "isAccess_df_batch1_rest.to_excel(batch_pathRest + '/isAccess_batch1_rest.xlsx', index=False)\n",
    "isErrors_df_batch1_rest.to_excel(batch_pathRest + '/isErrors_batch1_rest.xlsx', index=False)\n",
    "isTreatments_df_batch1_rest.to_excel(batch_pathRest + '/isTreatments_batch1_rest.xlsx', index=False)\n",
    "isStaffAndTrust_df_batch1_rest.to_excel(batch_pathRest + '/isStaffAndTrust_batch1_rest.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
